#!/usr/bin/env python3
"""
üöÄ –°–ö–†–ò–ü–¢ –î–õ–Ø –ó–ê–ü–£–°–ö–ê –ü–ê–†–°–ò–ù–ì–ê –í–°–ï–• –ò–°–¢–û–ß–ù–ò–ö–û–í

–ü–∞—Ä—Å–∏—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å:
- Immobiliare.it
- Subito.it  
- Idealista.it

–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    cd src/parsers
    python run_all_scraping.py
    
–ò–ª–∏ –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞:
    python src/parsers/run_all_scraping.py
"""
import sys
import asyncio
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.parsers.immobiliare_scraper import ImmobiliareScraper
from src.parsers.subito_scraper import SubitoScraper
from src.parsers.idealista_scraper import IdealistaScraper
from src.services.scraping_service import ScrapingService
from src.db.database import SessionLocal

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def scrape_source(scraper, source_name: str):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
    try:
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞: {source_name}")
        listings = await scraper.scrape_multiple_pages(max_pages=10)
        logger.info(f"‚úÖ {source_name}: –ø–æ–ª—É—á–µ–Ω–æ {len(listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        return source_name, listings
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {source_name}: {e}")
        return source_name, []


async def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    """
    print("üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
    
    # –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    enable_geocoding = True
    
    if len(sys.argv) > 1 and sys.argv[1] == "--no-geo":
        enable_geocoding = False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º ScraperAPI –∫–ª—é—á
    from src.core.config import settings
    if not settings.SCRAPERAPI_KEY:
        print("‚ùå –û–®–ò–ë–ö–ê: SCRAPERAPI_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∫—Ä–∞–ø–µ—Ä—ã
    immobiliare_scraper = ImmobiliareScraper(enable_geocoding=enable_geocoding)
    subito_scraper = SubitoScraper(enable_geocoding=enable_geocoding)
    idealista_scraper = IdealistaScraper(enable_geocoding=enable_geocoding)
    scraping_service = ScrapingService()
    
    try:
        import time
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(
            scrape_source(immobiliare_scraper, "Immobiliare.it"),
            scrape_source(subito_scraper, "Subito.it"),
            scrape_source(idealista_scraper, "Idealista.it"),
            return_exceptions=True
        )
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_listings = []
        stats_by_source = {}
        
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {result}")
                continue
                
            source_name, listings = result
            stats_by_source[source_name] = len(listings)
            all_listings.extend(listings)
        
        if not all_listings:
            print("‚ùå –û–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ –≤ –æ–¥–Ω–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–µ!")
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        db = SessionLocal()
        try:
            saved_stats = scraping_service.save_listings_to_db(all_listings, db)
            
            # –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–≤–æ–¥–∫–∞
            from datetime import datetime, timedelta
            next_run = datetime.now() + timedelta(hours=1)
            
            print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {execution_time:.1f}—Å")
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
            for source, count in stats_by_source.items():
                print(f"   ‚Ä¢ {source}: {count} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
            
            print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î:")
            print(f"   ‚Ä¢ –ù–æ–≤—ã—Ö: {saved_stats['created']}")
            print(f"   ‚Ä¢ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {saved_stats['updated']}")
            print(f"   ‚Ä¢ –û–±—â–∏–π –∏—Ç–æ–≥: {len(all_listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
            
            print(f"\n‚è∞ –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫: {next_run.strftime('%H:%M %d.%m.%Y')} (—á–µ—Ä–µ–∑ 1—á)")
            
        finally:
            db.close()
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 