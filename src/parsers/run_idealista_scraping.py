#!/usr/bin/env python3
"""
üöÄ –°–ö–†–ò–ü–¢ –î–õ–Ø –ó–ê–ü–£–°–ö–ê –ü–ê–†–°–ò–ù–ì–ê IDEALISTA.IT

–ü–∞—Ä—Å–∏—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å Idealista.it –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    cd src/parsers
    python run_idealista_scraping.py
    
–ò–ª–∏ –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞:
    python src/parsers/run_idealista_scraping.py
    
–û–ø—Ü–∏–∏:
    --no-geo    –û—Ç–∫–ª—é—á–∏—Ç—å –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (–±—ã—Å—Ç—Ä–µ–µ)
"""
import sys
import asyncio
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.parsers.idealista_scraper import IdealistaScraper
from src.services.scraping_service import ScrapingService
from src.db.database import SessionLocal

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Idealista.it
    """
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ Idealista.it")
    
    # –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    enable_geocoding = True
    
    if len(sys.argv) > 1 and sys.argv[1] == "--no-geo":
        enable_geocoding = False
        print("‚ÑπÔ∏è –ì–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º ScraperAPI –∫–ª—é—á
    from src.core.config import settings
    if not settings.SCRAPERAPI_KEY:
        print("‚ùå –û–®–ò–ë–ö–ê: SCRAPERAPI_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
        print("–î–æ–±–∞–≤—å—Ç–µ SCRAPERAPI_KEY –≤ .env —Ñ–∞–π–ª")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã
    scraper = IdealistaScraper(enable_geocoding=enable_geocoding)
    scraping_service = ScrapingService()
    
    try:
        import time
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥
        logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ Idealista.it...")
        listings = await scraper.scrape_multiple_pages(max_pages=10)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞ Idealista.it:")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(listings)}")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {execution_time:.1f} —Å–µ–∫")
        print(f"   ‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å: {len(listings)/execution_time:.1f} –æ–±—ä—è–≤–ª–µ–Ω–∏–π/—Å–µ–∫")
        
        if not listings:
            print("‚ö†Ô∏è –û–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ ScraperAPI –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–∞–π—Ç–∞.")
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º {len(listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        
        db = SessionLocal()
        try:
            saved_count = 0
            updated_count = 0
            
            for listing in listings:
                try:
                    result = scraping_service.save_listing(db, listing)
                    if result == "created":
                        saved_count += 1
                    elif result == "updated":
                        updated_count += 1
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∏—è {listing.get('external_id', 'unknown')}: {e}")
                    continue
            
            db.commit()
            
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ:")
            print(f"   ‚Ä¢ –ù–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {saved_count}")
            print(f"   ‚Ä¢ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {updated_count}")
            print(f"   ‚Ä¢ –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {saved_count + updated_count}/{len(listings)}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö: {e}")
            db.rollback()
        finally:
            db.close()
        
        # –ü—Ä–∏–º–µ—Ä—ã –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        if listings:
            print(f"\nüìã –ü–µ—Ä–≤—ã–µ 3 –æ–±—ä—è–≤–ª–µ–Ω–∏—è:")
            for i, listing in enumerate(listings[:3], 1):
                print(f"\n{i}. {listing.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:60]}...")
                print(f"   üí∞ –¶–µ–Ω–∞: {listing.get('price', 0)}‚Ç¨/–º–µ—Å—è—Ü")
                if listing.get('area'):
                    print(f"   üìê –ü–ª–æ—â–∞–¥—å: {listing.get('area')} –º¬≤")
                if listing.get('rooms'):
                    print(f"   üö™ –ö–æ–º–Ω–∞—Ç—ã: {listing.get('rooms')}")
                print(f"   üìç –ê–¥—Ä–µ—Å: {listing.get('address', 'N/A')}")
                if listing.get('latitude') and listing.get('longitude'):
                    print(f"   üó∫Ô∏è –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {listing.get('latitude'):.4f}, {listing.get('longitude'):.4f}")
                print(f"   üîó URL: {listing.get('url', 'N/A')[:80]}...")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 