#!/usr/bin/env python3
"""
üß™ –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –°–ö–†–ê–ü–ò–ù–ì - –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π

–ü–æ–∑–≤–æ–ª—è–µ—Ç –±—ã—Å—Ç—Ä–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ –ë–î –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
"""
import sys
import os
import asyncio
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent))

from src.parsers.immobiliare_scraper import ImmobiliareScraper
from src.crud.crud_listing import listing as crud_listing
import sqlalchemy
from sqlalchemy.orm import sessionmaker

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –æ–Ω–ª–∞–π–Ω –ë–î Railway
DATABASE_URL = 'postgresql://postgres:TAkDvHCdDTxVzutQsNNfJgbcSttzrgzN@caboose.proxy.rlwy.net:15179/railway'
engine = sqlalchemy.create_engine(DATABASE_URL, echo=False)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

async def quick_scrape_test(page_url: str = None, max_listings: int = 5):
    """
    –ë—ã—Å—Ç—Ä—ã–π —Å–∫—Ä–∞–ø–∏–Ω–≥ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    
    Args:
        page_url: URL –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞
        max_listings: –º–∞–∫—Å–∏–º—É–º –æ–±—ä—è–≤–ª–µ–Ω–∏–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
    """
    print("üß™ –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –°–ö–†–ê–ü–ò–ù–ì –î–õ–Ø –û–¢–õ–ê–î–ö–ò –£–í–ï–î–û–ú–õ–ï–ù–ò–ô")
    print("=" * 60)
    
    if not page_url:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π –ø–æ –¥–∞—Ç–µ
        page_url = "https://www.immobiliare.it/affitto-case/roma/?criterio=data&ordine=desc"
    
    print(f"üéØ URL: {page_url}")
    print(f"üìä –ú–∞–∫—Å–∏–º—É–º –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {max_listings}")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∞–ø–µ—Ä —Å –≥–µ–æ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    scraper = ImmobiliareScraper(enable_geocoding=True)
    
    try:
        print("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∞–ø–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ URL
        if "pag=" in page_url:
            import re
            page_match = re.search(r'pag=(\d+)', page_url)
            page_num = int(page_match.group(1)) if page_match else 1
        else:
            page_num = 1
            
        print(f"üìÑ –°–∫—Ä–∞–ø–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}")
        
        # –°–∫—Ä–∞–ø–∏–º –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É
        listings = await scraper.scrape_single_page(page_num)
        
        if not listings:
            print("‚ùå –û–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return 0
            
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        listings = listings[:max_listings]
        print(f"üìã –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ {len(listings)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        db = SessionLocal()
        saved_count = 0
        
        try:
            for i, listing_data in enumerate(listings, 1):
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
                    existing = crud_listing.get_by_external_id(
                        db, 
                        external_id=listing_data["external_id"],
                        source=listing_data["source"]
                    )
                    
                    if existing:
                        print(f"   ‚ö†Ô∏è  {i}. ID {listing_data['external_id']} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                        continue
                    
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
                    from src.schemas.listing import ListingCreate
                    listing_schema = ListingCreate(**listing_data)
                    new_listing = crud_listing.create(db, obj_in=listing_schema)
                    saved_count += 1
                    
                    print(f"   ‚úÖ {i}. –î–æ–±–∞–≤–ª–µ–Ω–æ: {new_listing.title[:50]}...")
                    print(f"      üí∞ {new_listing.price}‚Ç¨ | üè† {new_listing.property_type} | üìç {new_listing.city}")
                    
                    if new_listing.city == "Roma" and new_listing.property_type == "house":
                        print(f"      üéØ –ü–û–î–•–û–î–ò–¢ –ü–û–î –§–ò–õ–¨–¢–†! (–¥–æ–º –≤ –†–∏–º–µ)")
                    
                except Exception as e:
                    print(f"   ‚ùå {i}. –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
                    continue
            
            db.commit()
            print(f"\nüéâ –£–°–ü–ï–®–ù–û –î–û–ë–ê–í–õ–ï–ù–û: {saved_count} –Ω–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
            
            if saved_count > 0:
                print(f"\nüì± –°–õ–ï–î–£–Æ–©–ò–ô –®–ê–ì:")
                print(f"   –°–∏—Å—Ç–µ–º–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –Ω–∞–π–¥–µ—Ç –Ω–æ–≤—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è")
                print(f"   –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç –∏—Ö –≤ Telegram –≤ —Ç–µ—á–µ–Ω–∏–µ 5 –º–∏–Ω—É—Ç!")
            
            return saved_count
            
        finally:
            db.close()
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞: {e}")
        return 0
    
    finally:
        # –°–∫—Ä–∞–ø–µ—Ä –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∑–∞–∫—Ä—ã—Ç–∏—è –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏
        pass

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Å–∫—Ä–∞–ø–∏–Ω–≥ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏")
    parser.add_argument("--url", type=str, help="URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞")
    parser.add_argument("--max", type=int, default=5, help="–ú–∞–∫—Å–∏–º—É–º –æ–±—ä—è–≤–ª–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5)")
    parser.add_argument("--page", type=int, help="–ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã (1-10)")
    
    args = parser.parse_args()
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã, —Å—Ç—Ä–æ–∏–º URL
    if args.page:
        base_url = "https://www.immobiliare.it/affitto-case/roma/?criterio=data&ordine=desc"
        if args.page == 1:
            page_url = base_url
        else:
            page_url = f"{base_url}&pag={args.page}"
        print(f"üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {args.page}")
    else:
        page_url = args.url
    
    try:
        result = asyncio.run(quick_scrape_test(page_url, args.max))
        if result > 0:
            print(f"\nüöÄ –ì–û–¢–û–í–û! –î–æ–±–∞–≤–ª–µ–Ω–æ {result} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")
        sys.exit(0)
    except KeyboardInterrupt:
        print(f"\n‚èπÔ∏è –°–∫—Ä–∞–ø–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 